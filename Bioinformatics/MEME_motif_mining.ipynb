{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "alphabet = \"ATGC\"\n",
    "sequences = [\n",
    "    \"AGG\", \"CGT\", \"AGC\"\n",
    "]\n",
    "motif_len = 2\n",
    "pseudocount_constant = 1\n",
    "\n",
    "def to_base(seq):\n",
    "    return ''.join([\"ATGC \"[x] for x in seq])\n",
    "\n",
    "def likelihood(x, f, is_motif):\n",
    "    if is_motif == True:\n",
    "        prob = [f[pos+1, c] for (pos, c) in enumerate(x)]\n",
    "    else:\n",
    "        prob = [f[0, c] for c in x]\n",
    "    return np.prod(prob)\n",
    "\n",
    "def full_log_likelihood(X, Z, lamda, f):\n",
    "    log_likelihood = 0\n",
    "    for i in range(len(X)):\n",
    "        for j in (0, 1):\n",
    "            log_likelihood += Z[i, j] * (np.log(likelihood(X[i], f, j)) + np.log(lamda[j]))\n",
    "    return log_likelihood\n",
    "\n",
    "kmer_split = sum([[seq[i:i+motif_len] for i in range(len(seq)-motif_len+1)] for seq in sequences], [])\n",
    "alphabet_dict = {'A':0, 'T':1, 'G':2, 'C':3}\n",
    "sequences = [list(map(lambda c : alphabet_dict[c], seq)) for seq in kmer_split]\n",
    "num_alphabet = len(alphabet)\n",
    "num_sequences = len(sequences)\n",
    "\n",
    "# Initialize theta = (lambda, f)\n",
    "lamda_old = np.float32((0.5, 0.5))\n",
    "f_old = np.float32(\n",
    "    [ \n",
    "        [.25, .25, .25, .25],\n",
    "        [1/6, 1/6, 1/2, 1/6],\n",
    "        [1/6, 1/6, 1/6, 1/2]\n",
    "    ]\n",
    ")\n",
    "\n",
    "for iteration in range(10):\n",
    "    # E Step : Compute expected value of latent variable\n",
    "    z = np.zeros((num_sequences, 2))\n",
    "    for i in range(num_sequences):\n",
    "        z[i, 0] = likelihood(sequences[i], f_old, False) * lamda_old[0] # Background\n",
    "        z[i, 1] = likelihood(sequences[i], f_old, True)  * lamda_old[1] # Motif\n",
    "    z = normalize(z, norm='l1').round(2)\n",
    "\n",
    "    # M step : Using z, compute MLE within model parameters lambda and f\n",
    "    lamda_new = normalize(z.sum(axis=0, keepdims=True), norm='l1').reshape(-1, 1)\n",
    "    c = np.zeros_like(f_old)\n",
    "    for i in range(num_sequences):\n",
    "        for j in range(motif_len):\n",
    "            c[0, sequences[i][j]] += z[i, 0]\n",
    "    for i in range(num_sequences):\n",
    "        for j in range(motif_len):\n",
    "            c[j+1, sequences[i][j]] += z[i, 1]\n",
    "    f_new = np.zeros_like(f_old)\n",
    "    for i in range(motif_len+1):\n",
    "        for j in range(num_alphabet):\n",
    "            f_new[i, j] = (c[i, j] + pseudocount_constant) / (c[i].sum() + pseudocount_constant * num_alphabet)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
